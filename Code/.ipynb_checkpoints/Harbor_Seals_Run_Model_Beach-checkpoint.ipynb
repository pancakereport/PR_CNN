{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6102fe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code modeled after https://github.com/madelinehayes/seabirdNET\n",
    "# note: code is almost identical to Harbor_Seals_Run_Model_Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7759e36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "%run \"../keras-retinanet/keras_retinanet/bin/train.py\" --weights ../keras-retinanet/Models/resnet50_coco_best_v2.1.0.h5 \\\n",
    "--batch-size 2 --steps 30 --epochs 17 \\\n",
    "--snapshot-path ..\\Data\\Habor_Beach \\\n",
    "--random-transform \\\n",
    "--config harbor_config.ini \\\n",
    "csv ../Images/Harbor_Seals_Beach_Only/harbor_train_annotations.csv ../Images/Harbor_Seals_Beach_Only/harbor_classes.csv \\\n",
    "--val-annotations ../Images/Harbor_Seals_Beach_Only/harbor_val_annotations.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c726531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert model stored at second arg and store in path (final arg)\n",
    "%run \"../keras-retinanet/keras_retinanet/bin/convert_model.py\" --config harbor_config.ini ../Data/Habor_Beach/resnet50_csv_16.h5 ../Data/final_model_harbor_seal_beach_only_best.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703b1ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on the test set containing only beach tiles\n",
    "%run \"../keras-retinanet/keras_retinanet/bin/evaluate.py\" csv ../Images/Harbor_Seals_Beach_Only/harbor_test_annotations_beach_only.csv ../Data/harbor_seal_correct_annotations/harbor_classes.csv ../Data/final_model_harbor_seal_beach_only_best.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8be94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras_retinanet.models import retinanet\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from keras_retinanet.utils.colors import label_color\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "from random import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_session():\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.compat.v1.Session(config=config)\n",
    "\n",
    "tf.compat.v1.keras.backend.set_session(get_session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bc83b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../keras-retinanet/keras_retinanet')\n",
    "from utils.gpu import setup_gpu\n",
    "\n",
    "# use this to change which GPU to use\n",
    "gpu = '1'\n",
    "\n",
    "# set the modified tf session as backend in keras\n",
    "setup_gpu(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7dda8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../Data/final_model_harbor_seal_beach_only_best.h5'\n",
    "\n",
    "#print(model_path)\n",
    "\n",
    "model = models.load_model(model_path, backbone_name='resnet50')\n",
    "\n",
    "#print(model.summary())\n",
    "\n",
    "labels_to_names = {0: 'seal'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9544421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"../Images/Harbor_Seals_Beach_Only/\"\n",
    "\n",
    "image_list = []\n",
    "for root, dirs, files in os.walk(image_dir):\n",
    "    for filename in files:\n",
    "        if filename.lower().endswith(('.png')):\n",
    "            image_list.append(image_dir2 + filename)\n",
    "print(len(image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f2e0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize output for 10 random images\n",
    "visualize = True\n",
    "min_score = 0.5\n",
    "\n",
    "detections1 = {}\n",
    "\n",
    "total_time = 0\n",
    "\n",
    "count = 0\n",
    "detection_iterations = 10\n",
    "shuffle(image_list)\n",
    "\n",
    "for image_path in image_list: \n",
    "    if count > detection_iterations:\n",
    "        break\n",
    "    else: \n",
    "        count +=1\n",
    "    \n",
    "    image = read_image_bgr(image_path)\n",
    "    \n",
    "    if visualize:\n",
    "        draw = image.copy()\n",
    "        draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "    image = preprocess_image(image)\n",
    "    image, scale = resize_image(image)\n",
    "    \n",
    "    start = time.time()\n",
    "    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "    total_time += time.time() - start \n",
    "    \n",
    "    boxes /= scale\n",
    "    if any(score >= min_score for score in scores [0]):\n",
    "        detections1[image_path] = []\n",
    "    \n",
    "    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "        if score < min_score:\n",
    "            break\n",
    "        \n",
    "        b = box.astype(int)\n",
    "        detections1[image_path].append({\"box\" : b, \"label\" : label, \"score\" : score})\n",
    "        \n",
    "        if visualize: \n",
    "            color = label_color(label)\n",
    "            \n",
    "            draw_box(draw, b, color=color)\n",
    "            \n",
    "            caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
    "            draw_caption(draw, b, caption)\n",
    "            \n",
    "    if any(score >= min_score for score in scores[0]):\n",
    "        if visualize:\n",
    "            plt.figure(figsize=(15, 15))\n",
    "            plt.axis('off')\n",
    "            plt.imshow(draw)\n",
    "            plt.show()\n",
    "            \n",
    "print(\"Finished, time per image:\", total_time/len(image_list1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e348159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run through all images\n",
    "min_score = 0.5\n",
    "\n",
    "detections = {}\n",
    "\n",
    "total_time = 0\n",
    "\n",
    "for image_path in image_list:\n",
    "    \n",
    "    image = read_image_bgr(image_path)\n",
    "          \n",
    "    image = preprocess_image(image)\n",
    "    image, scale = resize_image(image)\n",
    "    \n",
    "    start = time.time()\n",
    "    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "    total_time += time.time() - start\n",
    "    \n",
    "    boxes /= scale  \n",
    "        \n",
    "    if any(score >= min_score for score in scores[0]):\n",
    "        detections[image_path] = []\n",
    "        \n",
    "    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "        if score < min_score:\n",
    "            break\n",
    "        \n",
    "        b = box.astype(int)    \n",
    "        detections[image_path].append({\"box\" : b, \"label\" : label, \"score\" : score})\n",
    "        \n",
    "            \n",
    "print(\"Finished, time per image:\", total_time/len(image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653a455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(MyEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c84795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write detections\n",
    "with open('../Data/harbor_beach_detections.json', 'w') as fp:\n",
    "    json.dump(detections, fp, cls=MyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3409421e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(detections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf53821c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
