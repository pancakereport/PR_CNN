{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3061bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre parse\n",
      "post arg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post generator\n",
      "Creating model, this may take a second...\n",
      "WARNING:tensorflow:Skipping loading of weights for layer classification_submodel due to mismatch in shape ((3, 3, 256, 9) vs (3, 3, 256, 720)).\n",
      "WARNING:tensorflow:Skipping loading of weights for layer classification_submodel due to mismatch in shape ((9,) vs (720,)).\n",
      "model summary here\n",
      "start training\n",
      "WARNING:tensorflow:From C:\\Users\\mgiff\\thesis\\PR_CNN\\PR_CNN\\keras-retinanet\\keras_retinanet\\bin\\train.py:564: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "%run \"../keras-retinanet/keras_retinanet/bin/train.py\" --weights ../keras-retinanet/Models/resnet50_coco_best_v2.1.0.h5 \\\n",
    "--batch-size 2 --steps 300 --epochs 30 \\\n",
    "--snapshot-path ../Images \\\n",
    "--random-transform \\\n",
    "--config test_config.ini \\\n",
    "csv ../Images/Harbor_Seals_Tile_Old/harbor_train_annotations.csv ../Images/Harbor_Seals_Tile_Old/harbor_classes.csv \\\n",
    "--val-annotations ../Images/Harbor_Seals_Tile_Old/harbor_val_annotations.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27e2fdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code similar to https://github.com/madelinehayes/seabirdNET/blob/master/albatross_detections_FINAL.ipynb and\n",
    "# the example file in keras-retinanet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae8f41fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# automatically reload modules when they have changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import keras\n",
    "from tensorflow import keras\n",
    "\n",
    "#\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, '../keras-retinanet/keras_retinanet')\n",
    "  \n",
    "import models\n",
    "from utils.image import read_image_bgr\n",
    "import utils.visualization\n",
    "import utils.colors\n",
    "from utils.gpu import setup_gpu\n",
    "\n",
    "# use this to change which GPU to use\n",
    "gpu = '1'\n",
    "\n",
    "# set the modified tf session as backend in keras\n",
    "setup_gpu(gpu)\n",
    "\n",
    "# import keras_retinanet\n",
    "#from keras_retinanet import models\n",
    "#from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "#from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "#from keras_retinanet.utils.colors import label_color\n",
    "#from keras_retinanet.utils.gpu import setup_gpu\n",
    "\n",
    "# import miscellaneous modules\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import time\n",
    "import json\n",
    "from random import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_session():\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.compat.v1.Session(config=config)\n",
    "\n",
    "tf.compat.v1.keras.backend.set_session(get_session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbfbc101",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpu =  ##fix me\n",
    "#setup_gpu(gpu)\n",
    "\n",
    "tf.config.threading.set_inter_op_parallelism_threads(12) ##fix me\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2806b8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from utils.visualization import draw_box, draw_caption\n",
    "from utils.colors import label_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e9fb3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model_path = '../keras-retinanet/Models/resnet50_coco_best_v2.1.0.h5'\n",
    "model = models.load_model(model_path, backbone_name='resnet50')\n",
    "labels_to_names = {0: 'seal'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e9d5ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = models.convert_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64ce714e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "image_dir = \"../Images/google_earth_test/\"\n",
    "\n",
    "image_list = []\n",
    "for root, dirs, files in os.walk(image_dir):\n",
    "    for filename in files:\n",
    "        if filename.lower().endswith(('.jpg')):\n",
    "            image_list.append(image_dir + filename)\n",
    "print(len(image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cb88439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished, time per image: 7.163912415504456\n"
     ]
    }
   ],
   "source": [
    "visualize = True\n",
    "min_score = 0.5\n",
    "\n",
    "detections = {}\n",
    "\n",
    "total_time = 0\n",
    "\n",
    "count = 0\n",
    "detection_iterations = 10\n",
    "shuffle(image_list)\n",
    "\n",
    "for image_path in image_list: \n",
    "    if count > detection_iterations:\n",
    "        break\n",
    "    else: \n",
    "        count +=1\n",
    "    \n",
    "    image = read_image_bgr(image_path)\n",
    "    \n",
    "    if visualize:\n",
    "        draw = image.copy()\n",
    "        draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "    image = preprocess_image(image)\n",
    "    image, scale = resize_image(image)\n",
    "    \n",
    "    start = time.time()\n",
    "    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "    total_time += time.time() - start \n",
    "    \n",
    "    boxes /= scale\n",
    "    if any(score >= min_score for score in scores [0]):\n",
    "        detections[image_path] = []\n",
    "    \n",
    "    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "        if score < min_score:\n",
    "            break\n",
    "        \n",
    "        b = box.astype(int)\n",
    "        detections[image_path].append({\"box\" : b, \"label\" : label, \"score\" : score})\n",
    "        \n",
    "        if visualize: \n",
    "            color = label_color(label)\n",
    "            \n",
    "            draw_box(draw, b, color=color)\n",
    "            \n",
    "            caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
    "            draw_caption(draw, b, caption)\n",
    "            \n",
    "    if any(score >= min_score for score in scores[0]):\n",
    "        if visualize:\n",
    "            plt.figure(figsize=(15, 15))\n",
    "            plt.axis('off')\n",
    "            plt.imshow(draw)\n",
    "            plt.show()\n",
    "            \n",
    "#try colab ??\n",
    "print(\"Finished, time per image:\", total_time/len(image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9e18eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(detections) #empty because model isn't trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf669c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output: detection boxes (#)/image\n",
    "#some way to keep track of confidence and use manual review below a certain threshold \n",
    "#some way to visualize this or "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
